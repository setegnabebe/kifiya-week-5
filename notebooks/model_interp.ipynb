{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import shap\n",
    "import lime\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from transformers import (pipeline, AutoTokenizer, AutoModelForTokenClassification)\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the model and tokenizer (for interpretability, choose one model, e.g., XLM-Roberta)\n",
    "model_name = \"xlm-roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All NaN and empty values have been cleaned from the texts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input type: <class 'list'>, Content: ['💥3pcs silicon brush spatulas\\n\\n⚡እስከ 260°c ሙቀት መቆቆም የሚችል\\n\\xa0\\xa0\\xa0\\xa0\\xa0 \\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 ዋጋ-550ብር✅\\n\\n🏢 አድራሻ\\xa0 ቁ.1👉 ስሪ ኤም ሲቲ ሞል\\xa0 ሁለተኛ ፎቅ ቢሮ ቁ. SL-05A(ከ ሊፍቱ ፊት ለ ፊት)\\n\\n📍ቁ.2 👉ለቡ\\xa0 መዳህኒዓለም ቤተ/ክርስቲያን ፊት ለፊት\\xa0 #ዛም_ሞል 2ኛ ፎቅ ቢሮ ቁጥር.214\\n\\n👍ለቡ\\xa0ቅርንጫፍ📲0973611819\\n\\n\\n\\n\\xa0\\xa0\\xa0 📲 0909522840\\n\\xa0\\xa0\\xa0 📲 0923350054\\n\\n🔖\\n💬\\xa0 በTelegram ለማዘዝ ⤵️ ይጠቀሙ\\n@shager_onlinestore\\n\\xa0 \\nለተጨማሪ ማብራሪያ የቴሌግራም ገፃችን⤵️\\nhttps://t.me/Shageronlinestore', '💥Mandoline Slicer\\n\\n👉 ጊዜ ቆጣቢ ስላይስ ማድረጊያ \\n👉\\xa0 ለእጅ ሴፍቲ ተመራጭ\\n👉\\xa0 ለድንች ለካሮትና ሌሎች አታክልቶች ተመራጭ \\n👉ጥራት ያለው ዕቃ\\n\\n\\xa0\\xa0\\xa0  ዋጋ፦ ✅ 1,200 ብር\\n\\n🏢 አድራሻ\\xa0 ቁ.1👉 ስሪ ኤም ሲቲ ሞል\\xa0 ሁለተኛ ፎቅ ቢሮ ቁ. SL-05A(ከ ሊፍቱ ፊት ለ ፊት)\\n\\n📍ቁ.2 👉ለቡ\\xa0 መዳህኒዓለም ቤተ/ክርስቲያን ፊት ለፊት\\xa0 #ዛም_ሞል 2ኛ ፎቅ ቢሮ ቁጥር.214\\n\\n👍ለቡ\\xa0ቅርንጫፍ📲0973611819\\n\\n\\n\\n\\xa0\\xa0\\xa0 📲 0909522840\\n\\xa0\\xa0\\xa0 📲 0923350054\\n\\n🔖\\n💬\\xa0 በTelegram ለማዘዝ ⤵️ ይጠቀሙ\\n@shager_onlinestore\\n\\xa0 \\nለተጨማሪ ማብራሪያ የቴሌግራም ገፃችን⤵️\\nhttps://t.me/Shageronlinestore', '💥Table Desk Edge Guard Strip\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 💯 High Quality \\n\\n👉Made from soft, environmentally friendly, fireproof and non-toxic material.\\n\\n👉Help to protect your child from the sharp edges and corners at home\\n👉Suitable for wood, bakelite, ceramic tile, marble, glass, metal corner, etc\\n👉Total length 2m, suitable for different sizes of furniture.\\n\\n#Package_Included:\\n1* Table Desk Edge Guard Strip\\n1 * Double-sided Adhesive\\n\\nዋጋ፦\\xa0 💰🏷\\xa0 2meter:- 500 ብር✅\\n\\n♦️ውስን ፍሬ ነው ያለው\\n\\n🏢 አድራሻ\\xa0 ቁ.1👉 ስሪ ኤም ሲቲ ሞል\\xa0 ሁለተኛ ፎቅ ቢሮ ቁ. SL-05A(ከ ሊፍቱ ፊት ለ ፊት)\\n\\n📍ቁ.2 👉ለቡ\\xa0 መዳህኒዓለም ቤተ/ክርስቲያን ፊት ለፊት\\xa0 #ዛም_ሞል 2ኛ ፎቅ ቢሮ ቁጥር.214\\n\\n👍ለቡ\\xa0ቅርንጫፍ📲0973611819\\n\\n\\n\\xa0\\xa0\\xa0\\xa0 💧💧💧💧\\n\\n\\n\\xa0\\xa0\\xa0 📲 0909522840\\n\\xa0\\xa0\\xa0 📲 0923350054\\n\\n🔖\\n💬\\xa0 በTelegram ለማዘዝ ⤵️ ይጠቀሙ\\n@shager_onlinestore\\n\\xa0 \\nለተጨማሪ ማብራሪያ የቴሌግራም ገፃችን⤵️\\nhttps://t.me/Shageronlinestore', '💥Table Desk Edge Guard Strip\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 💯 High Quality \\n\\n👉Made from soft, environmentally friendly, fireproof and non-toxic material.\\n\\n👉Help to protect your child from the sharp edges and corners at home\\n👉Suitable for wood, bakelite, ceramic tile, marble, glass, metal corner, etc\\n👉Total length 2m, suitable for different sizes of furniture.\\n\\n#Package_Included:\\n1* Table Desk Edge Guard Strip\\n1 * Double-sided Adhesive\\n\\nዋጋ፦\\xa0 💰🏷\\xa0 2meter:- 500 ብር✅\\n\\n♦️ውስን ፍሬ ነው ያለው\\n\\n🏢 አድራሻ\\xa0 ቁ.1👉 ስሪ ኤም ሲቲ ሞል\\xa0 ሁለተኛ ፎቅ ቢሮ ቁ. SL-05A(ከ ሊፍቱ ፊት ለ ፊት)\\n\\n📍ቁ.2 👉ለቡ\\xa0 መዳህኒዓለም ቤተ/ክርስቲያን ፊት ለፊት\\xa0 #ዛም_ሞል 2ኛ ፎቅ ቢሮ ቁጥር.214\\n\\n👍ለቡ\\xa0ቅርንጫፍ📲0973611819\\n\\n\\n\\xa0\\xa0\\xa0\\xa0 💧💧💧💧\\n\\n\\n\\xa0\\xa0\\xa0 📲 0909522840\\n\\xa0\\xa0\\xa0 📲 0923350054\\n\\n🔖\\n💬\\xa0 በTelegram ለማዘዝ ⤵️ ይጠቀሙ\\n@shager_onlinestore\\n\\xa0 \\nለተጨማሪ ማብራሪያ የቴሌግራም ገፃችን⤵️\\nhttps://t.me/Shageronlinestore', '💥Only baby 3in1 double bottle milk warmer,sterilizer,food steamer\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 ዋጋ:-3000ብር✅\\n\\n❌ውስን ፍሬ ነው ያለው\\n\\n🏢 አድራሻ\\xa0 ቁ.1👉 ስሪ ኤም ሲቲ ሞል\\xa0 ሁለተኛ ፎቅ ቢሮ ቁ. SL-05A(ከ ሊፍቱ ፊት ለ ፊት)\\n\\n📍ቁ.2 👉ለቡ\\xa0 መዳህኒዓለም ቤተ/ክርስቲያን ፊት ለፊት\\xa0 #ዛም_ሞል 2ኛ ፎቅ ቢሮ ቁጥር.214\\n\\n👍ለቡ\\xa0ቅርንጫፍ📲0973611819\\n\\n\\n\\n\\xa0\\xa0\\xa0\\xa0 💧💧💧💧\\n\\n\\n\\xa0\\xa0\\xa0 📲 0909522840\\n\\xa0\\xa0\\xa0 📲 0923350054\\n\\n🔖\\n💬\\xa0 በTelegram ለማዘዝ ⤵️ ይጠቀሙ\\n@shager_onlinestore\\n\\xa0 \\nለተጨማሪ ማብራሪያ የቴሌግራም ገፃችን⤵️\\nhttps://t.me/Shageronlinestore', '💥Only baby 3in1 double bottle milk warmer,sterilizer,food steamer\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 ዋጋ:-3000ብር✅\\n\\n❌ውስን ፍሬ ነው ያለው\\n\\n🏢 አድራሻ\\xa0 ቁ.1👉 ስሪ ኤም ሲቲ ሞል\\xa0 ሁለተኛ ፎቅ ቢሮ ቁ. SL-05A(ከ ሊፍቱ ፊት ለ ፊት)\\n\\n📍ቁ.2 👉ለቡ\\xa0 መዳህኒዓለም ቤተ/ክርስቲያን ፊት ለፊት\\xa0 #ዛም_ሞል 2ኛ ፎቅ ቢሮ ቁጥር.214\\n\\n👍ለቡ\\xa0ቅርንጫፍ📲0973611819\\n\\n\\n\\n\\xa0\\xa0\\xa0\\xa0 💧💧💧💧\\n\\n\\n\\xa0\\xa0\\xa0 📲 0909522840\\n\\xa0\\xa0\\xa0 📲 0923350054\\n\\n🔖\\n💬\\xa0 በTelegram ለማዘዝ ⤵️ ይጠቀሙ\\n@shager_onlinestore\\n\\xa0 \\nለተጨማሪ ማብራሪያ የቴሌግራም ገፃችን⤵️\\nhttps://t.me/Shageronlinestore', '💥1pc stainless steel loaf pan\\n\\n👍ትልቁ\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 ዋጋ:-ትልቁ:-800ብር✅\\n\\n❌ውስን ፍሬ ነው ያለው\\n\\n🏢 አድራሻ\\xa0 ቁ.1👉 ስሪ ኤም ሲቲ ሞል\\xa0 ሁለተኛ ፎቅ ቢሮ ቁ. SL-05A(ከ ሊፍቱ ፊት ለ ፊት)\\n\\n📍ቁ.2 👉ለቡ\\xa0 መዳህኒዓለም ቤተ/ክርስቲያን ፊት ለፊት\\xa0 #ዛም_ሞል 2ኛ ፎቅ ቢሮ ቁጥር.214\\n\\n👍ለቡ\\xa0ቅርንጫፍ📲0973611819\\n\\n\\xa0\\xa0\\xa0 📲 0909522840\\n\\xa0\\xa0\\xa0 📲 0923350054\\n\\n🔖\\n💬\\xa0 በTelegram ለማዘዝ ⤵️ ይጠቀሙ\\n@shager_onlinestore\\n\\xa0 \\nለተጨማሪ ማብራሪያ የቴሌግራም ገፃችን⤵️\\nhttps://t.me/Shageronlinestore', '📣Geemy Rechargable Hair\\xa0 Clipper\\n\\n✔️ የፀጉርና የፂም መቁረጪያ ቶንዶስ\\n✔️ በቻርጅ የሚሰራ \\n✔️ ከ3-4 ሰዓት ቻርጅ ተደርጎ ከ240-300 ደቂቃ\\xa0 ይጠቀሙበታል\\n✔️ መለዋወጫ 4 ጥርስ ያለው\\n✔️ 2000mA ባትሪ\\n✔️ በየትኛውም የሰውነት ክፍል የሚበቅል ፀጉርን ሙልጭጭ አድርጎ ይቆርጣል፤ ቅርፅም ያወጣል\\n🤫 ፀጉር ቤት ይዘውት ቢጠቀሙበት የሚያኮራ\\n✔️ የባትሪ መጠን ማሳያ ስክሪን ያለው\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0 ዋጋ:-2100 ብር💵\\n\\n❌ውስን ፍሬ ነው ያለው\\n\\n🏢 አድራሻ\\xa0 ቁ.1👉 ስሪ ኤም ሲቲ ሞል\\xa0 ሁለተኛ ፎቅ ቢሮ ቁ. SL-05A(ከ ሊፍቱ ፊት ለ ፊት)\\n\\n📍ቁ.2 👉ለቡ\\xa0 መዳህኒዓለም ቤተ/ክርስቲያን ፊት ለፊት\\xa0 #ዛም_ሞል 2ኛ ፎቅ ቢሮ ቁጥር.214\\n\\n👍ለቡ\\xa0ቅርንጫፍ📲0973611819\\n\\n\\xa0\\xa0\\xa0\\xa0 \\n\\xa0\\xa0\\xa0 📲 0909522840\\n\\xa0\\xa0\\xa0 📲 0923350054\\n\\n🔖\\n💬\\xa0 በTelegram ለማዘዝ ⤵️ ይጠቀሙ\\n@shager_onlinestore\\n\\xa0 \\nለተጨማሪ ማብራሪያ የቴሌግራም ገፃችን⤵️\\nhttps://t.me/Shageronlinestore', '💥 kids water bottle\\n\\n\\xa0👉ጠንካራ እና እማይሰበር\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0ዋጋ:-450ml:-600ብር✅\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 800ml:-650ብር✅\\n\\n🏢 አድራሻ\\xa0 ቁ.1👉 መገናኝ ስሪ ኤም ሲቲ ሞል\\xa0 ሁለተኛ ፎቅ ቢሮ ቁ. SL-05A(ከ ሊፍቱ ፊት ለ ፊት)\\n\\n📍ቁ.2 👉ለቡ\\xa0 መዳህኒዓለም ቤተ/ክርስቲያን ፊት ለፊት\\xa0 #ዛም_ሞል 2ኛ ፎቅ ቢሮ ቁጥር.214\\n\\n\\n👍ለቡ\\xa0ቅርንጫፍ📲0973611819\\n\\n\\xa0\\xa0\\xa0\\xa0 \\n\\n\\n\\xa0\\xa0\\xa0 📲 0909522840\\n\\xa0\\xa0\\xa0 📲 0923350054\\n\\n🔖\\n💬\\xa0 በTelegram ለማዘዝ ⤵️ ይጠቀሙ\\n@shager_onlinestore\\n\\xa0 \\nለተጨማሪ ማብራሪያ የቴሌግራም ገፃችን⤵️\\nhttps://t.me/Shageronlinestore', '💥4Pcs isolated lunch box with bag \\n\\n⚡️በውስጡ 4 የምሳ ዕቃወች የያዘ\\n⚡️leakp️roof\\n⚡️stainless still food grade materials\\n⚡️ምግብዎን ሳያቀዘቅዝ እንደሞቀ ሚያቆይ\\n\\xa0\\xa0\\xa0\\xa0\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 🟠በቢሮዎ ውስጥ\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 🍵 ለልጆች ትምህርት ቤት\\n\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0 ዋጋ:-3200ብር✅\\n\\n\\n✖️ውስን ፍሬ ነው ያለን\\n\\n\\n🏢 አድራሻ\\xa0 ቁ.1👉 መገናኛ ስሪ ኤም ሲቲ ሞል\\xa0 ሁለተኛ ፎቅ ቢሮ ቁ. SL-05A(ከ ሊፍቱ ፊት ለ ፊት)\\n\\n📍ቁ.2 👉ለቡ\\xa0 መዳህኒዓለም ቤተ/ክርስቲያን ፊት ለፊት\\xa0 #ዛም_ሞል 2ኛ ፎቅ ቢሮ ቁጥር.214\\n\\n\\n👍ለቡ\\xa0ቅርንጫፍ📲0973611819\\n\\n\\n\\xa0\\xa0\\xa0\\n\\n\\xa0\\xa0\\xa0 📲 0909522840\\n\\xa0\\xa0\\xa0 📲 0923350054\\n\\n🔖\\n💬\\xa0 በTelegram ለማዘዝ ⤵️ ይጠቀሙ\\n@shager_onlinestore\\n\\xa0 \\nለተጨማሪ ማብራሪያ የቴሌግራም ገፃችን⤵️\\nhttps://t.me/Shageronlinestore']\n",
      "Input format is correct.\n",
      "Type of input: <class 'numpy.ndarray'>\n",
      "Contents of input: ['[MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]']\n",
      "Error while explaining SHAP values: Input must be a list of strings.\n",
      "SHAP values could not be computed due to previous errors.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import shap\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "# Load your CSV data\n",
    "csv_file_path = '../data/cleaned_telegram_data.csv'  # Update this with your CSV file path\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Clean the 'Message' column by dropping NaN values and converting to strings\n",
    "data['Message'] = data['Message'].dropna().astype(str)\n",
    "\n",
    "# Convert the cleaned column to a list of strings\n",
    "texts = data['Message'].tolist()\n",
    "\n",
    "# Check for any NaN or empty values after cleaning\n",
    "if any(pd.isna(texts)) or any(text == \"\" for text in texts):\n",
    "    print(\"There are still NaN or empty values in the texts.\")\n",
    "else:\n",
    "    print(\"All NaN and empty values have been cleaned from the texts.\")\n",
    "\n",
    "# Define your model name (change this to your specific model)\n",
    "model_name = \"dbmdz/bert-large-cased-finetuned-conll03-english\"  # Example model\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "# 1. SHAP Explanation\n",
    "# Prepare the function to predict token classification\n",
    "def predict_shap(texts):\n",
    "    # Ensure input is a list of strings\n",
    "    print(f\"Type of input: {type(texts)}\")\n",
    "    print(f\"Contents of input: {texts}\")\n",
    "\n",
    "    if isinstance(texts, list) and all(isinstance(text, str) for text in texts):\n",
    "        # Tokenize all texts at once, ensure it's a list of strings\n",
    "        inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        predicted_classes = logits.argmax(dim=-1)  # Get predicted classes\n",
    "        \n",
    "        # Return predictions as a list of lists\n",
    "        return predicted_classes.tolist()  # Convert to list of lists\n",
    "    else:\n",
    "        raise ValueError(\"Input must be a list of strings.\")\n",
    "\n",
    "# Create a new explainer that directly works with the model's predictions\n",
    "explainer = shap.Explainer(predict_shap, tokenizer)\n",
    "\n",
    "# Limit the number of texts for SHAP to avoid memory issues\n",
    "num_samples = min(10, len(texts))  # Change 10 to any number you want to visualize\n",
    "\n",
    "# Get a sample of texts\n",
    "sample_texts = texts[:num_samples]  # Get a sample of texts\n",
    "print(f\"Sample input type: {type(sample_texts)}, Content: {sample_texts}\")\n",
    "\n",
    "# Ensure the sample input is indeed a list of strings\n",
    "if isinstance(sample_texts, list) and all(isinstance(text, str) for text in sample_texts):\n",
    "    print(\"Input format is correct.\")\n",
    "else:\n",
    "    print(\"Input format is incorrect.\")\n",
    "    raise ValueError(\"Input must be a list of strings.\")  # Raise error for debugging\n",
    "\n",
    "# Pass a slice of the data to the explainer\n",
    "shap_values = None  # Initialize shap_values to None\n",
    "try:\n",
    "    shap_values = explainer(sample_texts)  # Ensure this is a list of strings\n",
    "except ValueError as e:\n",
    "    print(f\"Error while explaining SHAP values: {e}\")\n",
    "\n",
    "# Check if shap_values was defined before attempting to visualize\n",
    "if shap_values is not None:\n",
    "    # Visualization of SHAP values\n",
    "    for i in range(num_samples):\n",
    "        shap.plots.text(shap_values[i])  # This will show which tokens contributed to the NER decision\n",
    "else:\n",
    "    print(\"SHAP values could not be computed due to previous errors.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All NaN and empty values have been cleaned from the texts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import shap\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "# Load your CSV data\n",
    "csv_file_path = '../data/cleaned_telegram_data.csv'  # Update this with your CSV file path\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Clean the 'Message' column by dropping NaN values and converting to strings\n",
    "data['Message'] = data['Message'].dropna().astype(str)\n",
    "\n",
    "# Convert the cleaned column to a list of strings\n",
    "texts = data['Message'].tolist()\n",
    "\n",
    "# Check for any NaN or empty values after cleaning\n",
    "if any(pd.isna(texts)) or any(text == \"\" for text in texts):\n",
    "    print(\"There are still NaN or empty values in the texts.\")\n",
    "else:\n",
    "    print(\"All NaN and empty values have been cleaned from the texts.\")\n",
    "\n",
    "# Define your model name (change this to your specific model)\n",
    "model_name = \"dbmdz/bert-large-cased-finetuned-conll03-english\"  # Example model\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "# Initialize NER pipeline\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "class_names = [f\"Class {i}\" for i in range(len(model.config.id2label))]  # Update class names based on your model\n",
    "lime_explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "# Use LIME to explain NER output\n",
    "def lime_predict_proba(texts):\n",
    "    output = []\n",
    "    for text in texts:\n",
    "        result = ner_pipeline(text)\n",
    "        proba = np.zeros(len(text))\n",
    "        for item in result:\n",
    "            # Simple binary marking of entities\n",
    "            proba[item['start']:item['end']] = 1  \n",
    "        output.append(proba)\n",
    "    return np.array(output)\n",
    "\n",
    "# Example text to explain\n",
    "text_example = \"John Smith went to the bank.\"  \n",
    "\n",
    "\n",
    "lime_explanation = lime_explainer.explain_instance(text_example, lime_predict_proba, num_features=6)\n",
    "\n",
    "# Visualize explanation\n",
    "lime_explanation.show_in_notebook(text=True)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
